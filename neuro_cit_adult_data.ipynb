{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d379bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adult_data_functions as af\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import os \n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29467f84",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb37b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "categorical_feature_encoder = preprocessing.OneHotEncoder()\n",
    "sex_encoder = preprocessing.LabelEncoder() \n",
    "race_encoder = preprocessing.LabelEncoder()\n",
    "income_encoder = preprocessing.LabelEncoder()\n",
    "# train_data_dict = af.preprocess(adult_dt_path=\"data/adult.data\", \n",
    "#                                 categorical_feature_encoder=categorical_feature_encoder, \n",
    "#                                 sex_encoder=sex_encoder, race_encoder=race_encoder, \n",
    "#                                 income_encoder=income_encoder, encoder_fit_boolean=True)\n",
    "train_data_dict, excessive_data_dict = \\\n",
    "    af.preprocess(adult_dt_path=\"data/adult.data\", \n",
    "                  categorical_feature_encoder=categorical_feature_encoder, \n",
    "                  sex_encoder=sex_encoder, race_encoder=race_encoder, \n",
    "                  income_encoder=income_encoder, encoder_fit_boolean=True,\n",
    "                  drop_prop_male_poor=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45272b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sex', 'race', 'income-label', 'categorical-features', 'continuous-features'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e079b",
   "metadata": {},
   "source": [
    "## Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecbbac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21972"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_array = np.arange(train_data_dict[\"income-label\"].shape[0])\n",
    "len(indices_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "feb5ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split based on income\n",
    "train_indices_array, val_indices_array = train_test_split(indices_array, \n",
    "                                                           stratify=train_data_dict[\"income-label\"], \n",
    "                                                           test_size=0.1, \n",
    "                                                           random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "639d2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_train_dataset = \\\n",
    "    tf.data.Dataset.from_tensor_slices(train_data_dict[\"categorical-features\"][train_indices_array, :].toarray())\n",
    "categorical_feature_val_dataset = \\\n",
    "    tf.data.Dataset.from_tensor_slices(train_data_dict[\"categorical-features\"][val_indices_array, :].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c50aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_feature_train_dataset = \\\n",
    "    tf.data.Dataset.from_tensor_slices(train_data_dict[\"continuous-features\"].iloc[train_indices_array, :])\n",
    "continuous_feature_val_dataset = \\\n",
    "    tf.data.Dataset.from_tensor_slices(train_data_dict[\"continuous-features\"].iloc[val_indices_array, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94e3193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_dataset = tf.data.Dataset.zip((continuous_feature_train_dataset, categorical_feature_train_dataset))\n",
    "feature_val_dataset = tf.data.Dataset.zip((continuous_feature_val_dataset, categorical_feature_val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6b93b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare x_y_mat (sex, income)\n",
    "x_y_mat = np.hstack([train_data_dict[\"sex\"].reshape(-1, 1), train_data_dict[\"income-label\"].reshape(-1, 1)])\n",
    "x_y_mat = 2 * x_y_mat - 1\n",
    "response_train_dataset = tf.data.Dataset.from_tensor_slices(x_y_mat[train_indices_array, :])\n",
    "response_val_dataset = tf.data.Dataset.from_tensor_slices(x_y_mat[val_indices_array, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e843915",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.zip((feature_train_dataset, response_train_dataset))\n",
    "val_dataset = tf.data.Dataset.zip((feature_val_dataset, response_val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd98b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 50000\n",
    "batch_size = 20000\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "val_dataset = val_dataset.shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fcc1e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23fc4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_sex_metric = af.Metric(name=\"f1\", response_name=\"sex\")\n",
    "f1_income_metric = af.Metric(name=\"f1\", response_name=\"income-label\")\n",
    "accuracy_sex_metric = af.Metric(name=\"accuracy\", response_name=\"sex\")\n",
    "accuracy_income_metric = af.Metric(name=\"accuracy\", response_name=\"income-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2b019da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = af.BranchesModel(n_shared_layers=1, shared_hidden_dim=0, shared_output_dim=2, \n",
    "#                          n_x_layers=0, x_hidden_dim=0, n_y_layers=0, y_hidden_dim=0, \n",
    "#                          education_dim=5, occupation_dim=5,\n",
    "#                         shared_regularizer=tf.keras.regularizers.L2(0.05), x_regularizer=None, \n",
    "#                         y_regularizer=None)\n",
    "\n",
    "# model = af.BranchesModel(n_shared_layers=3, shared_hidden_dim=60, shared_output_dim=60, n_x_layers=2, x_hidden_dim=40,\n",
    "#                       n_y_layers=2, y_hidden_dim=40, education_dim=5, occupation_dim=5)\n",
    "\n",
    "model = af.ModelNetwork(n_layers=0, hidden_dim=None, final_dim=59)\n",
    "# model_args_dict = {\"n_layers\": 1, \"final_dim\": 0, \"hidden_dim\": None, \n",
    "#                    \"education_dim\": None, \"occupation_dim\": None}\n",
    "# model = af.ModelNetwork(**model_args_dict)\n",
    "# model.initialize();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4998e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bf9c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=af.ising_likelihood, \n",
    "              metrics=[f1_sex_metric, f1_income_metric, accuracy_sex_metric, accuracy_income_metric],\n",
    "              run_eagerly=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=1,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=f\"saved_model/model_{epoch},\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    " \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71172a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 63356.9453 - f1_sex: 0.6568 - f1_income-label: 0.5260 - accuracy_sex: 0.4891 - accuracy_income-label: 0.3569 - val_loss: 60976.3125 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5014 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 60976.31250, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 60160.6406 - f1_sex: 0.6569 - f1_income-label: 0.5260 - accuracy_sex: 0.4892 - accuracy_income-label: 0.3569 - val_loss: 57742.2383 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5014 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00002: val_loss improved from 60976.31250 to 57742.23828, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 56964.9141 - f1_sex: 0.6569 - f1_income-label: 0.5260 - accuracy_sex: 0.4893 - accuracy_income-label: 0.3569 - val_loss: 54508.2734 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5014 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00003: val_loss improved from 57742.23828 to 54508.27344, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 53769.5352 - f1_sex: 0.6569 - f1_income-label: 0.5260 - accuracy_sex: 0.4894 - accuracy_income-label: 0.3568 - val_loss: 51274.2031 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5014 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00004: val_loss improved from 54508.27344 to 51274.20312, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 50574.3906 - f1_sex: 0.6570 - f1_income-label: 0.5259 - accuracy_sex: 0.4895 - accuracy_income-label: 0.3568 - val_loss: 48040.2383 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5014 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00005: val_loss improved from 51274.20312 to 48040.23828, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 47380.6797 - f1_sex: 0.6570 - f1_income-label: 0.5256 - accuracy_sex: 0.4896 - accuracy_income-label: 0.3565 - val_loss: 44806.9180 - val_f1_sex: 0.6681 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5018 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00006: val_loss improved from 48040.23828 to 44806.91797, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 44187.7539 - f1_sex: 0.6571 - f1_income-label: 0.5255 - accuracy_sex: 0.4899 - accuracy_income-label: 0.3564 - val_loss: 41576.4062 - val_f1_sex: 0.6677 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5014 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00007: val_loss improved from 44806.91797 to 41576.40625, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 40997.4453 - f1_sex: 0.6574 - f1_income-label: 0.5254 - accuracy_sex: 0.4905 - accuracy_income-label: 0.3563 - val_loss: 38347.9727 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5018 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00008: val_loss improved from 41576.40625 to 38347.97266, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 37811.1328 - f1_sex: 0.6574 - f1_income-label: 0.5252 - accuracy_sex: 0.4908 - accuracy_income-label: 0.3561 - val_loss: 35120.5898 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5258 - val_accuracy_sex: 0.5018 - val_accuracy_income-label: 0.3567\n",
      "\n",
      "Epoch 00009: val_loss improved from 38347.97266 to 35120.58984, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 34628.5156 - f1_sex: 0.6574 - f1_income-label: 0.5250 - accuracy_sex: 0.4910 - accuracy_income-label: 0.3560 - val_loss: 31895.9277 - val_f1_sex: 0.6679 - val_f1_income-label: 0.5248 - val_accuracy_sex: 0.5018 - val_accuracy_income-label: 0.3558\n",
      "\n",
      "Epoch 00010: val_loss improved from 35120.58984 to 31895.92773, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 31451.5684 - f1_sex: 0.6577 - f1_income-label: 0.5243 - accuracy_sex: 0.4919 - accuracy_income-label: 0.3553 - val_loss: 28675.5801 - val_f1_sex: 0.6683 - val_f1_income-label: 0.5243 - val_accuracy_sex: 0.5027 - val_accuracy_income-label: 0.3553\n",
      "\n",
      "Epoch 00011: val_loss improved from 31895.92773 to 28675.58008, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 28284.7246 - f1_sex: 0.6582 - f1_income-label: 0.5232 - accuracy_sex: 0.4932 - accuracy_income-label: 0.3543 - val_loss: 25463.5859 - val_f1_sex: 0.6689 - val_f1_income-label: 0.5243 - val_accuracy_sex: 0.5041 - val_accuracy_income-label: 0.3553\n",
      "\n",
      "Epoch 00012: val_loss improved from 28675.58008 to 25463.58594, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 25125.2402 - f1_sex: 0.6584 - f1_income-label: 0.5217 - accuracy_sex: 0.4937 - accuracy_income-label: 0.3529 - val_loss: 22259.0957 - val_f1_sex: 0.6693 - val_f1_income-label: 0.5238 - val_accuracy_sex: 0.5050 - val_accuracy_income-label: 0.3549\n",
      "\n",
      "Epoch 00013: val_loss improved from 25463.58594 to 22259.09570, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 21975.6484 - f1_sex: 0.6587 - f1_income-label: 0.5195 - accuracy_sex: 0.4945 - accuracy_income-label: 0.3510 - val_loss: 19067.7930 - val_f1_sex: 0.6687 - val_f1_income-label: 0.5209 - val_accuracy_sex: 0.5045 - val_accuracy_income-label: 0.3521\n",
      "\n",
      "Epoch 00014: val_loss improved from 22259.09570 to 19067.79297, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 36s 36s/step - loss: 18836.0254 - f1_sex: 0.6591 - f1_income-label: 0.5183 - accuracy_sex: 0.4953 - accuracy_income-label: 0.3499 - val_loss: 15888.4697 - val_f1_sex: 0.6691 - val_f1_income-label: 0.5195 - val_accuracy_sex: 0.5055 - val_accuracy_income-label: 0.3512\n",
      "\n",
      "Epoch 00015: val_loss improved from 19067.79297 to 15888.46973, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 15704.0498 - f1_sex: 0.6595 - f1_income-label: 0.5167 - accuracy_sex: 0.4963 - accuracy_income-label: 0.3484 - val_loss: 12718.8096 - val_f1_sex: 0.6697 - val_f1_income-label: 0.5180 - val_accuracy_sex: 0.5068 - val_accuracy_income-label: 0.3499\n",
      "\n",
      "Epoch 00016: val_loss improved from 15888.46973 to 12718.80957, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 12584.0312 - f1_sex: 0.6599 - f1_income-label: 0.5143 - accuracy_sex: 0.4976 - accuracy_income-label: 0.3463 - val_loss: 9558.7598 - val_f1_sex: 0.6693 - val_f1_income-label: 0.5160 - val_accuracy_sex: 0.5068 - val_accuracy_income-label: 0.3480\n",
      "\n",
      "Epoch 00017: val_loss improved from 12718.80957 to 9558.75977, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 9477.4541 - f1_sex: 0.6604 - f1_income-label: 0.5118 - accuracy_sex: 0.4990 - accuracy_income-label: 0.3441 - val_loss: 6416.4111 - val_f1_sex: 0.6705 - val_f1_income-label: 0.5075 - val_accuracy_sex: 0.5109 - val_accuracy_income-label: 0.3403\n",
      "\n",
      "Epoch 00018: val_loss improved from 9558.75977 to 6416.41113, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 6388.0576 - f1_sex: 0.6613 - f1_income-label: 0.5046 - accuracy_sex: 0.5022 - accuracy_income-label: 0.3378 - val_loss: 3347.9473 - val_f1_sex: 0.6743 - val_f1_income-label: 0.4859 - val_accuracy_sex: 0.5241 - val_accuracy_income-label: 0.3221\n",
      "\n",
      "Epoch 00019: val_loss improved from 6416.41113 to 3347.94727, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 37s 37s/step - loss: 3355.7034 - f1_sex: 0.6635 - f1_income-label: 0.4856 - accuracy_sex: 0.5117 - accuracy_income-label: 0.3222 - val_loss: 673.0062 - val_f1_sex: 0.0465 - val_f1_income-label: 0.4391 - val_accuracy_sex: 0.4777 - val_accuracy_income-label: 0.2980\n",
      "\n",
      "Epoch 00020: val_loss improved from 3347.94727 to 673.00623, saving model to saved_model/model_20,\n",
      "INFO:tensorflow:Assets written to: saved_model/model_20,/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f918d383890>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.seed(0)\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407db69b",
   "metadata": {},
   "source": [
    "# Check Performance on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2425aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dict = af.preprocess(adult_dt_path=\"data/adult.test\", \n",
    "                                categorical_feature_encoder=categorical_feature_encoder, \n",
    "                                sex_encoder=sex_encoder, race_encoder=race_encoder, \n",
    "                                income_encoder=income_encoder, encoder_fit_boolean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12bebd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dict[\"continuous-features\"][\"age\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cc2fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_test_dataset = \\\n",
    "    tf.data.Dataset.from_tensor_slices(test_data_dict[\"categorical-features\"].toarray())\n",
    "continuous_feature_test_dataset = \\\n",
    "    tf.data.Dataset.from_tensor_slices(test_data_dict[\"continuous-features\"].to_numpy().astype(\"float32\"))\n",
    "feature_test_dataset = tf.data.Dataset.zip((continuous_feature_test_dataset, categorical_feature_test_dataset))\n",
    "\n",
    "x_y_mat = np.hstack([test_data_dict[\"sex\"].reshape(-1, 1), test_data_dict[\"income-label\"].reshape(-1, 1)])\n",
    "x_y_mat = 2 * x_y_mat - 1\n",
    "\n",
    "test_dataset = tf.data.Dataset.zip((feature_test_dataset, tf.data.Dataset.from_tensor_slices(x_y_mat)))\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3cf9a",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fc6868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex-1</th>\n",
       "      <td>0.332965</td>\n",
       "      <td>0.332965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income1</th>\n",
       "      <td>0.763774</td>\n",
       "      <td>0.763774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision  recall        f1\n",
       "sex-1    0.332965   0.332965     1.0  0.499585\n",
       "income1  0.763774   0.763774     1.0  0.866068"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af.tf_score_summary(model=model, dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bda0aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = af.ising_predict(model(list(test_dataset.take(1))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fa1c67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16281, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_test_f1 = f1_score(test_data_dict[\"income-label\"], pred_test_x_y_mat[:, 1])\n",
    "sex_test_f1 = f1_score(test_data_dict[\"sex\"], pred_test_x_y_mat[:, 0])\n",
    "\n",
    "print(f\"income test f1 is {income_test_f1}\")\n",
    "print(f\"sex test f1 is {sex_test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a850e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum(x_y_mat[:, 1]==-1)/x_y_mat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1400ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
