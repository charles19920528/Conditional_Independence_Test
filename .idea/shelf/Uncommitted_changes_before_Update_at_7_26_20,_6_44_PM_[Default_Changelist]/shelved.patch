Index: ising_test_statistic_level_simulation.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import time\nimport multiprocessing as mp\nimport os\nimport numpy as np\nimport simulation_functions as sf\nimport generate_train_functions as gt\nimport tensorflow as tf\nimport hyperparameters as hp\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n\npool = mp.Pool(processes=hp.process_number)\nnp.random.seed(1)\ntf.random.set_seed(1)\n\n# Set up\nmixture_result_dict_name = f\"mixture_data_{hp.mixture_number_forward_layer}_{hp.mixture_hidden_dim}\"\nmixture_network_model_class_kwargs = {\"number_forward_layers\": hp.mixture_number_forward_layer,\n                                      \"input_dim\": hp.dim_z, \"hidden_dim\": hp.mixture_hidden_dim, \"output_dim\": 3}\nmixture_network_model_class_kwargs_vet = [mixture_network_model_class_kwargs for _ in range(len(hp.sample_size_vet))]\n\ntrue_result_dict_name = f\"ising_data_true_architecture\"\ntrue_network_model_class_kwargs = {\"number_forward_layers\": 1, \"input_dim\": hp.dim_z,\n                                   \"hidden_dim\": hp.hidden_1_out_dim, \"output_dim\": 3}\ntrue_network_model_class_kwargs_vet = [true_network_model_class_kwargs for _ in range(len(hp.sample_size_vet))]\n\ntrial_index_vet = np.arange(100)\nsample_size_vet = [hp.sample_size_vet[1]]\nmax_epoch_vet = [hp.mixture_epoch_vet[1]]\n\n# Mixture datamax_epoch_vet,\n# Null data\n# start_time = time.time()\n# sf.ising_bootstrap_loop(pool=pool, data_directory_name=\"mixture_data\", scenario=\"null\",\n#                         ising_simulation_result_dict_name=mixture_result_dict_name,\n#                         result_dict_name=\"bootstrap_mixture_100\",\n#                         trial_index_vet=trial_index_vet, network_model_class=gt.FullyConnectedNetwork,\n#                         network_model_class_kwargs_vet=mixture_network_model_class_kwargs_vet,\n#                         number_of_bootstrap_samples=hp.number_of_boostrap_samples, max_epoch_vet=max_epoch_vet,\n#                         sample_size_vet=sample_size_vet)\n#\n# print(f\"Bootstrap simulation under mixture null data takes {time.time() - start_time} seconds to finish.\")\n\n\n\nsample_size_vet = [hp.sample_size_vet[2]]\nmax_epoch_vet = [hp.mixture_epoch_vet[2]]\nstart_time = time.time()\nsf.ising_bootstrap_loop(pool=pool, data_directory_name=\"mixture_data\", scenario=\"alt\",\n                        ising_simulation_result_dict_name=mixture_result_dict_name,\n                        result_dict_name=\"bootstrap_mixture_500\",\n                        trial_index_vet=np.arange(20), network_model_class=gt.FullyConnectedNetwork,\n                        network_model_class_kwargs_vet=mixture_network_model_class_kwargs_vet,\n                        number_of_bootstrap_samples=hp.number_of_boostrap_samples, max_epoch_vet=max_epoch_vet,\n                        sample_size_vet=sample_size_vet)\n\nprint(f\"Bootstrap simulation under mixture alt data takes {time.time() - start_time} seconds to finish.\")\npool.close()\npool.join()\n\n# import pickle\n# with open('results/result_dict/mixture_data/bootstrap_mixture_null_result_dict.p', 'rb') as fp:\n#     bootstrap_mixture_null_result_dict = pickle.load(fp)\n\n\"\"\"\nNot in use\n####################################\n# Simulate argmax Gaussian Process #\n####################################\nnp.random.seed(hp.seed_index)\ntf.random.set_seed(hp.seed_index)\n\n# Ising\n# Null data\nstart_time = time.time()\nsf.argmax_simulation_loop(pool=pool, trial_index_vet=np.arange(hp.number_of_trials), sample_size_vet=hp.sample_size_vet,\n                          scenario=\"null\", data_directory_name=\"ising_data\",\n                          ising_simulation_result_dict_name=true_result_dict_name,\n                          network_model_class=gt.FullyConnectedNetwork,\n                          network_model_class_kwargs_vet=true_network_model_class_kwargs_vet,\n                          network_net_size=hp.network_net_size, number_of_nets=hp.number_of_nets,\n                          result_dict_name=\"gaussian_process\")\n\nprint(f\"Gaussian process simulation under null Ising data takes {time.time() - start_time} seconds to finish.\")\n\n\n# Alt\nstart_time = time.time()\nsf.argmax_simulation_loop(pool=pool, trial_index_vet=np.arange(hp.number_of_trials), sample_size_vet=[1000],\n                          scenario=\"alt\", data_directory_name=\"ising_data\",\n                          ising_simulation_result_dict_name=true_result_dict_name,\n                          network_model_class=gt.FullyConnectedNetwork,\n                          network_model_class_kwargs_vet=true_network_model_class_kwargs_vet,\n                          network_net_size=hp.network_net_size, number_of_nets=hp.number_of_nets,\n                          result_dict_name=\"gaussian_process\")\n\nprint(f\"Gaussian process simulation under alternative Ising data takes {time.time() - start_time} seconds to finish.\")\n\"\"\"
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- ising_test_statistic_level_simulation.py	(revision 26f33e53037ac34241e9e5289b435403f07b91ce)
+++ ising_test_statistic_level_simulation.py	(date 1595720630298)
@@ -6,7 +6,6 @@
 import generate_train_functions as gt
 import tensorflow as tf
 import hyperparameters as hp
-
 os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
 
 pool = mp.Pool(processes=hp.process_number)
Index: ising_tuning.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import numpy as np\nimport tensorflow as tf\nimport ising_tuning_functions as it\nimport generate_train_functions as gt\nimport hyperparameters as hp\nimport os\nimport pickle\nimport multiprocessing as mp\nimport time\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n\ntrial_index_vet = np.arange(120)\nsample_size_vet = hp.sample_size_vet\n\nif len(trial_index_vet) < hp.process_number:\n    process_number = len(trial_index_vet)\nelse:\n    process_number = hp.process_number\n\npool = mp.Pool(processes=process_number)\n\n##########################################\n# Fit the full model on the mixture data #\n##########################################\n# 1 layer\nnumber_forward_layers = 1\nhidden_dim_mixture_vet = [10, 20, 50, 100, 200, 500, 700]\nmixture_result_dict_name_vet = [f\"mixture_{number_forward_layers}_{hidden_dim}_{hp.learning_rate_mixture}\"\n                                for hidden_dim in hidden_dim_mixture_vet]\n\nepoch_vet = [500, 300, 150, 100]\nnp.random.seed(hp.seed_index)\ntf.random.set_seed(hp.seed_index)\n\nfor hidden_dim_mixture, result_dict_name in zip(hidden_dim_mixture_vet, mixture_result_dict_name_vet):\n    one_layer_network_kwargs_dict = {\"number_forward_layers\": number_forward_layers, \"input_dim\": hp.dim_z,\n                                     \"hidden_dim\": hidden_dim_mixture, \"output_dim\": 3}\n    it.tuning_wrapper(pool=pool, scenario=\"alt\", data_directory_name=\"mixture_data\",\n                      network_model_class=gt.FullyConnectedNetwork,\n                      number_of_test_samples_vet=hp.number_of_test_samples_vet, epoch_vet=epoch_vet,\n                      trial_index_vet=trial_index_vet, result_dict_name=result_dict_name,\n                      network_model_class_kwargs=one_layer_network_kwargs_dict,\n                      sample_size_vet=hp.sample_size_vet, learning_rate=hp.learning_rate,\n                      weights_or_radius_kwargs={\"cut_off_radius\": hp.alt_cut_off_radius})\n\n    print(f\"hidden_dim {hidden_dim_mixture} finished.\")\n\n# Analysis results.\nfor mixture_result_dict_name in mixture_result_dict_name_vet:\n    tuning_result_dict_name = mixture_result_dict_name + \"_alt\"\n    it.process_plot_epoch_kl_raw_dict(pool=pool, tuning_result_dict_name=tuning_result_dict_name,\n                                      sample_size_vet=sample_size_vet, trial_index_vet=trial_index_vet)\n\nfor sample_size, epoch in zip(sample_size_vet, epoch_vet):\n    it.plot_loss_kl(scenario=\"alt\", tuning_result_dict_name=mixture_result_dict_name_vet[4],\n                    trial_index_vet=[0, 10, 49, 60],\n                    sample_size=sample_size, end_epoch=epoch, start_epoch=0, plot_train_loss_boolean=True,\n                    plot_kl_boolean=True, plot_test_loss_boolean=True)\n\n# When hidden dim is between 100 and 200, the kl seems to be smaller when sample size is 500 and 100. When hidden dim is\n#   large, the kl is smaller when sample size is 100. Still is is pretty bad about 0.33.\n\n# When sample size is 50 or 100, there seems to be overfitting problem.\n\n\n##################################\n# Fit null model on mixture data #\n##################################\none_layer_null_network_kwargs_dict = {\"number_forward_layers\": 1, \"input_dim\": hp.dim_z,\n                                     \"hidden_dim\": 200, \"output_dim\": 2}\nmixture_reduced_result_dict_name = \"mixture_reduced_model\"\nepoch_vet = [500, 300, 150, 100]\nnp.random.seed(hp.seed_index)\ntf.random.set_seed(hp.seed_index)\n\nit.tuning_wrapper(pool=pool, scenario=\"alt\", data_directory_name=\"mixture_data\",\n                  network_model_class=gt.FullyConnectedNetwork,\n                  number_of_test_samples_vet=hp.number_of_test_samples_vet, epoch_vet=epoch_vet,\n                  trial_index_vet=trial_index_vet, result_dict_name=mixture_reduced_result_dict_name,\n                  network_model_class_kwargs=one_layer_null_network_kwargs_dict,\n                  sample_size_vet=hp.sample_size_vet, learning_rate=hp.learning_rate,\n                  weights_or_radius_kwargs={\"cut_off_radius\": hp.alt_cut_off_radius})\n\n\ntuning_result_dict_name = mixture_reduced_result_dict_name + \"_alt\"\nit.process_plot_epoch_kl_raw_dict(pool=pool, tuning_result_dict_name=tuning_result_dict_name,\n                                  sample_size_vet=sample_size_vet, trial_index_vet=trial_index_vet)\n\nfor sample_size, epoch in zip(sample_size_vet, epoch_vet):\n    it.plot_loss_kl(scenario=\"alt\", tuning_result_dict_name=mixture_reduced_result_dict_name,\n                    trial_index_vet=[0, 10, 49, 60],\n                    sample_size=sample_size, end_epoch=epoch, start_epoch=0, plot_train_loss_boolean=True,\n                    plot_kl_boolean=True, plot_test_loss_boolean=True)\n# Median epoch is  8.  8. 12. 21.\n\nit.tuning_wrapper(pool=pool, scenario=\"null\", data_directory_name=\"mixture_data\",\n                  network_model_class=gt.FullyConnectedNetwork,\n                  number_of_test_samples_vet=hp.number_of_test_samples_vet, epoch_vet=epoch_vet,\n                  trial_index_vet=trial_index_vet, result_dict_name=mixture_reduced_result_dict_name,\n                  network_model_class_kwargs=one_layer_null_network_kwargs_dict,\n                  sample_size_vet=hp.sample_size_vet, learning_rate=hp.learning_rate,\n                  weights_or_radius_kwargs={\"cut_off_radius\": hp.alt_cut_off_radius})\n\ntuning_result_dict_name = mixture_reduced_result_dict_name + \"_null\"\nit.process_plot_epoch_kl_raw_dict(pool=pool, tuning_result_dict_name=tuning_result_dict_name,\n                                  sample_size_vet=sample_size_vet, trial_index_vet=trial_index_vet)\n\nfor sample_size, epoch in zip(sample_size_vet, epoch_vet):\n    it.plot_loss_kl(scenario=\"alt\", tuning_result_dict_name=mixture_reduced_result_dict_name,\n                    trial_index_vet=[0, 10, 49, 60],\n                    sample_size=sample_size, end_epoch=epoch, start_epoch=0, plot_train_loss_boolean=True,\n                    plot_kl_boolean=True, plot_test_loss_boolean=True)\n\n# Median epoch 8.  8. 12. 18.\n\n################################\n# Tuning for true Ising model #\n###############################\nnp.random.seed(hp.seed_index)\ntf.random.set_seed(hp.seed_index)\n\nepoch_vet = [500, 300, 150, 100]\n\ntrue_result_dict_name = f\"true_1_{hp.hidden_1_out_dim}_{hp.learning_rate_mixture}\"\ntrue_one_layer_network_kwargs_dict = {\"number_forward_layers\": 1, \"input_dim\": hp.dim_z,\n                                      \"hidden_dim\": hp.hidden_1_out_dim, \"output_dim\": 3}\ntrial_index_vet = np.arange(20)\nwith open('data/ising_data/weights_dict.p', 'rb') as fp:\n    true_weights_dict = pickle.load(fp)\n\nit.tuning_wrapper(pool=pool, scenario=\"alt\", data_directory_name=\"ising_data\",\n                  network_model_class=gt.FullyConnectedNetwork,\n                  number_of_test_samples_vet=hp.number_of_test_samples_vet, epoch_vet=epoch_vet,\n                  trial_index_vet=trial_index_vet, result_dict_name=true_result_dict_name,\n                  network_model_class_kwargs=true_one_layer_network_kwargs_dict,\n                  sample_size_vet=hp.sample_size_vet, learning_rate=hp.learning_rate,\n                  weights_or_radius_kwargs={\"true_weights_dict\": true_weights_dict})\n\nit.process_plot_epoch_kl_raw_dict(pool=pool, tuning_result_dict_name=true_result_dict_name+\"_alt\",\n                                      sample_size_vet=sample_size_vet, trial_index_vet=trial_index_vet)\n\nfor sample_size, epoch in zip(sample_size_vet, epoch_vet):\n    it.plot_loss_kl(scenario=\"alt\", tuning_result_dict_name=true_result_dict_name,\n                    trial_index_vet=[0, 10, 49, 60],\n                    sample_size=sample_size, end_epoch=epoch, start_epoch=0, plot_train_loss_boolean=True, plot_kl_boolean=True,\n                    plot_test_loss_boolean=True)\n\n# The median optimal epochs are  99, 129, 131, 91.\n# When sample size is 50 or 100, there seems to be overfitting problem.\n\npool.close()\npool.join()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- ising_tuning.py	(revision 26f33e53037ac34241e9e5289b435403f07b91ce)
+++ ising_tuning.py	(date 1595720557178)
@@ -6,7 +6,6 @@
 import os
 import pickle
 import multiprocessing as mp
-import time
 
 os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
 
