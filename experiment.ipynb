{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c8a931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adult_data_functions as af\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a67f0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_encoder = preprocessing.OneHotEncoder()\n",
    "sex_encoder = preprocessing.LabelEncoder() \n",
    "race_encoder = preprocessing.LabelEncoder()\n",
    "income_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "train_data_dict = af.preprocess(adult_dt_path=\"data/adult.data\", \n",
    "                                categorical_feature_encoder=categorical_feature_encoder, \n",
    "                                sex_encoder=sex_encoder, race_encoder=race_encoder, \n",
    "                                income_encoder=income_encoder, encoder_fit_boolean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d85e6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_array = np.arange(train_data_dict[\"income-label\"].shape[0])\n",
    "len(indices_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e88fb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split based on income\n",
    "train_indices_array, val_indices_array = train_test_split(indices_array, \n",
    "                                                           stratify=train_data_dict[\"income-label\"], \n",
    "                                                           test_size=0.1, \n",
    "                                                           random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb0490b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_x_train_mat = np.hstack([train_data_dict[\"categorical-features\"].toarray(), \n",
    "                                  train_data_dict[\"continuous-features\"].to_numpy()])\n",
    "# Prepare x_y_mat (sex, income)\n",
    "x_y_mat = np.hstack([train_data_dict[\"sex\"].reshape(-1, 1), train_data_dict[\"income-label\"].reshape(-1, 1)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "436aac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 50000\n",
    "batch_size = 20000\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebae5a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e716e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNetwork(tf.keras.Model):\n",
    "    # This is the class network we fit on the data.\n",
    "    def __init__(self, n_layers, hidden_dim, output_dim, final_layer_regularizer=None):\n",
    "\n",
    "        super(ModelNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_layer = af._create_connnected_block(n_layers=n_layers, hidden_dim=hidden_dim, \n",
    "                                                        output_dim=output_dim, regularizer=None)\n",
    "\n",
    "        self.final_linear = tf.keras.layers.Dense(\n",
    "            units=2,\n",
    "            activation=\"softmax\",\n",
    "            kernel_regularizer=final_layer_regularizer\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = inputs\n",
    "        if self.hidden_layer is not None:\n",
    "            for layer in self.hidden_layer:\n",
    "                output = layer(output)\n",
    "        output = self.final_linear(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb1e514",
   "metadata": {},
   "source": [
    "## Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84eea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((logistic_x_train_mat[train_indices_array, :], \n",
    "                                                    x_y_mat[train_indices_array, 1]))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((logistic_x_train_mat[val_indices_array, :], \n",
    "                                                   x_y_mat[val_indices_array, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a6f54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelNetwork(n_layers=0, hidden_dim=0, output_dim=0, \n",
    "                     final_layer_regularizer=tf.keras.regularizers.L2(10000))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92b4df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=1,\n",
    "        verbose=1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64c077b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 48336.1094 - sparse_categorical_accuracy: 0.7596 - val_loss: 47713.3594 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 47416.9453 - sparse_categorical_accuracy: 0.7596 - val_loss: 46800.6133 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 46508.6680 - sparse_categorical_accuracy: 0.7596 - val_loss: 45898.0820 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 45610.1875 - sparse_categorical_accuracy: 0.7596 - val_loss: 45005.9727 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 44724.1172 - sparse_categorical_accuracy: 0.7597 - val_loss: 44124.5312 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 43845.0586 - sparse_categorical_accuracy: 0.7597 - val_loss: 43254.0625 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 42979.3906 - sparse_categorical_accuracy: 0.7597 - val_loss: 42394.2734 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 42124.1797 - sparse_categorical_accuracy: 0.7597 - val_loss: 41545.3438 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 41279.5664 - sparse_categorical_accuracy: 0.7597 - val_loss: 40707.3203 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 40446.4922 - sparse_categorical_accuracy: 0.7597 - val_loss: 39880.1680 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 39623.5352 - sparse_categorical_accuracy: 0.7597 - val_loss: 39063.9453 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 38811.4336 - sparse_categorical_accuracy: 0.7598 - val_loss: 38258.5352 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 38010.6719 - sparse_categorical_accuracy: 0.7598 - val_loss: 37463.8086 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 37220.1602 - sparse_categorical_accuracy: 0.7598 - val_loss: 36679.7617 - val_sparse_categorical_accuracy: 0.7599\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 36440.0742 - sparse_categorical_accuracy: 0.7599 - val_loss: 35906.2539 - val_sparse_categorical_accuracy: 0.7599\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 35671.1562 - sparse_categorical_accuracy: 0.7599 - val_loss: 35143.1094 - val_sparse_categorical_accuracy: 0.7599\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 34912.0742 - sparse_categorical_accuracy: 0.7601 - val_loss: 34390.2891 - val_sparse_categorical_accuracy: 0.7599\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 34164.0508 - sparse_categorical_accuracy: 0.7602 - val_loss: 33647.6406 - val_sparse_categorical_accuracy: 0.7599\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 33425.6758 - sparse_categorical_accuracy: 0.7602 - val_loss: 32915.3672 - val_sparse_categorical_accuracy: 0.7608\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 32697.4570 - sparse_categorical_accuracy: 0.7604 - val_loss: 32193.1855 - val_sparse_categorical_accuracy: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0536599110>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "model.fit(train_dataset, epochs=20, validation_data=val_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52ba1a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.760823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.012674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.760823        1.0  0.006378  0.012674"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af.tf_score_summary(model=model, dataset=val_dataset, pos_label=1, \n",
    "                    activation=lambda x: tf.argmax(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf8d3f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.760823</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.86393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision  recall       f1\n",
       "0  0.760823   0.760455     1.0  0.86393"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af.tf_score_summary(model=model, dataset=val_dataset, pos_label=0, \n",
    "                    activation=lambda x: tf.argmax(x, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f88351",
   "metadata": {},
   "source": [
    "## Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5d52c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((logistic_x_train_mat[train_indices_array, :], \n",
    "                                                    x_y_mat[train_indices_array, 0]))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((logistic_x_train_mat[val_indices_array, :], \n",
    "                                                   x_y_mat[val_indices_array, 0]))\n",
    "\n",
    "buffer_size = 50000\n",
    "batch_size = 20000\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2dea0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.regularizers.L2(10000)\n",
    "model = ModelNetwork(n_layers=0, hidden_dim=0, output_dim=0, \n",
    "                     final_layer_regularizer=tf.keras.regularizers.L2(10000))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49b056b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4934.2847 - sparse_categorical_accuracy: 0.4586 - val_loss: 4836.7104 - val_sparse_categorical_accuracy: 0.6405\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4820.4160 - sparse_categorical_accuracy: 0.5541 - val_loss: 4726.1763 - val_sparse_categorical_accuracy: 0.6457\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4708.6587 - sparse_categorical_accuracy: 0.6373 - val_loss: 4619.8711 - val_sparse_categorical_accuracy: 0.3654\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4602.1377 - sparse_categorical_accuracy: 0.4649 - val_loss: 4512.9829 - val_sparse_categorical_accuracy: 0.6503\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4495.1440 - sparse_categorical_accuracy: 0.5636 - val_loss: 4406.5459 - val_sparse_categorical_accuracy: 0.6435\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4389.8462 - sparse_categorical_accuracy: 0.5529 - val_loss: 4308.1035 - val_sparse_categorical_accuracy: 0.6521\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4292.5000 - sparse_categorical_accuracy: 0.6432 - val_loss: 4204.7207 - val_sparse_categorical_accuracy: 0.6438\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4193.0967 - sparse_categorical_accuracy: 0.5519 - val_loss: 4114.3301 - val_sparse_categorical_accuracy: 0.3614\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4098.5444 - sparse_categorical_accuracy: 0.4642 - val_loss: 4025.2876 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4011.8542 - sparse_categorical_accuracy: 0.6448 - val_loss: 3928.4670 - val_sparse_categorical_accuracy: 0.6543\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3911.5679 - sparse_categorical_accuracy: 0.6433 - val_loss: 3846.0356 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3831.2366 - sparse_categorical_accuracy: 0.3768 - val_loss: 3735.3025 - val_sparse_categorical_accuracy: 0.4206\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3725.1313 - sparse_categorical_accuracy: 0.4988 - val_loss: 3667.2849 - val_sparse_categorical_accuracy: 0.6583\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3655.4785 - sparse_categorical_accuracy: 0.6469 - val_loss: 3577.8411 - val_sparse_categorical_accuracy: 0.6546\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3562.4419 - sparse_categorical_accuracy: 0.6450 - val_loss: 3491.1482 - val_sparse_categorical_accuracy: 0.3629\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3477.9690 - sparse_categorical_accuracy: 0.3776 - val_loss: 3397.4751 - val_sparse_categorical_accuracy: 0.6472\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3385.6384 - sparse_categorical_accuracy: 0.6407 - val_loss: 3319.0574 - val_sparse_categorical_accuracy: 0.6512\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3306.4097 - sparse_categorical_accuracy: 0.5560 - val_loss: 3238.5586 - val_sparse_categorical_accuracy: 0.6472\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3225.7708 - sparse_categorical_accuracy: 0.6392 - val_loss: 3167.9038 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3152.9763 - sparse_categorical_accuracy: 0.4605 - val_loss: 3085.8018 - val_sparse_categorical_accuracy: 0.6460\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3075.1565 - sparse_categorical_accuracy: 0.5541 - val_loss: 3013.8101 - val_sparse_categorical_accuracy: 0.6497\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3002.4248 - sparse_categorical_accuracy: 0.6425 - val_loss: 2938.9709 - val_sparse_categorical_accuracy: 0.4243\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2927.2012 - sparse_categorical_accuracy: 0.4337 - val_loss: 2872.3008 - val_sparse_categorical_accuracy: 0.6515\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2860.8687 - sparse_categorical_accuracy: 0.6427 - val_loss: 2805.4241 - val_sparse_categorical_accuracy: 0.3617\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2792.9473 - sparse_categorical_accuracy: 0.4606 - val_loss: 2734.0955 - val_sparse_categorical_accuracy: 0.6466\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2724.6646 - sparse_categorical_accuracy: 0.5578 - val_loss: 2669.0627 - val_sparse_categorical_accuracy: 0.6494\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2658.7144 - sparse_categorical_accuracy: 0.6420 - val_loss: 2604.7178 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2594.8340 - sparse_categorical_accuracy: 0.4596 - val_loss: 2543.9548 - val_sparse_categorical_accuracy: 0.6524\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2532.4897 - sparse_categorical_accuracy: 0.6272 - val_loss: 2492.7114 - val_sparse_categorical_accuracy: 0.3595\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2478.2742 - sparse_categorical_accuracy: 0.3755 - val_loss: 2431.2417 - val_sparse_categorical_accuracy: 0.6561\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2425.8989 - sparse_categorical_accuracy: 0.6474 - val_loss: 2383.7764 - val_sparse_categorical_accuracy: 0.6653\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2374.8086 - sparse_categorical_accuracy: 0.6519 - val_loss: 2311.8530 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2301.5090 - sparse_categorical_accuracy: 0.5630 - val_loss: 2254.4570 - val_sparse_categorical_accuracy: 0.3620\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2244.0183 - sparse_categorical_accuracy: 0.4609 - val_loss: 2199.8289 - val_sparse_categorical_accuracy: 0.6543\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2191.0845 - sparse_categorical_accuracy: 0.6442 - val_loss: 2137.3481 - val_sparse_categorical_accuracy: 0.6362\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2135.8086 - sparse_categorical_accuracy: 0.5441 - val_loss: 2102.6458 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2089.9373 - sparse_categorical_accuracy: 0.4512 - val_loss: 2046.1359 - val_sparse_categorical_accuracy: 0.6574\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2039.2643 - sparse_categorical_accuracy: 0.6463 - val_loss: 1992.1984 - val_sparse_categorical_accuracy: 0.6543\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1981.8057 - sparse_categorical_accuracy: 0.5742 - val_loss: 1944.7064 - val_sparse_categorical_accuracy: 0.3583\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1934.0221 - sparse_categorical_accuracy: 0.4556 - val_loss: 1890.7781 - val_sparse_categorical_accuracy: 0.6524\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1881.9561 - sparse_categorical_accuracy: 0.6379 - val_loss: 1856.8529 - val_sparse_categorical_accuracy: 0.3473\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1844.7437 - sparse_categorical_accuracy: 0.3636 - val_loss: 1807.8773 - val_sparse_categorical_accuracy: 0.6589\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1804.9921 - sparse_categorical_accuracy: 0.6499 - val_loss: 1775.3907 - val_sparse_categorical_accuracy: 0.6724\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1768.4392 - sparse_categorical_accuracy: 0.6567 - val_loss: 1716.2927 - val_sparse_categorical_accuracy: 0.6546\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 43ms/step - loss: 1709.5681 - sparse_categorical_accuracy: 0.5502 - val_loss: 1674.7061 - val_sparse_categorical_accuracy: 0.3426\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1666.3141 - sparse_categorical_accuracy: 0.4452 - val_loss: 1634.3518 - val_sparse_categorical_accuracy: 0.6586\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1628.2478 - sparse_categorical_accuracy: 0.6468 - val_loss: 1586.2280 - val_sparse_categorical_accuracy: 0.6527\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1583.1522 - sparse_categorical_accuracy: 0.5519 - val_loss: 1551.3993 - val_sparse_categorical_accuracy: 0.3331\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1545.5350 - sparse_categorical_accuracy: 0.4401 - val_loss: 1522.8521 - val_sparse_categorical_accuracy: 0.6666\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1518.4373 - sparse_categorical_accuracy: 0.6546 - val_loss: 1480.6909 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1472.0428 - sparse_categorical_accuracy: 0.6482 - val_loss: 1455.6497 - val_sparse_categorical_accuracy: 0.3212\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1449.2496 - sparse_categorical_accuracy: 0.3355 - val_loss: 1395.1947 - val_sparse_categorical_accuracy: 0.6494\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1391.5173 - sparse_categorical_accuracy: 0.6424 - val_loss: 1366.3904 - val_sparse_categorical_accuracy: 0.6540\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1359.3976 - sparse_categorical_accuracy: 0.6447 - val_loss: 1342.7179 - val_sparse_categorical_accuracy: 0.3245\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1333.5940 - sparse_categorical_accuracy: 0.3396 - val_loss: 1302.9728 - val_sparse_categorical_accuracy: 0.6613\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1301.7911 - sparse_categorical_accuracy: 0.6522 - val_loss: 1282.4957 - val_sparse_categorical_accuracy: 0.6733\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1277.1871 - sparse_categorical_accuracy: 0.6594 - val_loss: 1234.3350 - val_sparse_categorical_accuracy: 0.6546\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1231.8870 - sparse_categorical_accuracy: 0.5480 - val_loss: 1211.5884 - val_sparse_categorical_accuracy: 0.3267\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1202.9835 - sparse_categorical_accuracy: 0.4397 - val_loss: 1177.1245 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1173.0105 - sparse_categorical_accuracy: 0.6492 - val_loss: 1140.6409 - val_sparse_categorical_accuracy: 0.6537\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1138.7285 - sparse_categorical_accuracy: 0.5469 - val_loss: 1112.5370 - val_sparse_categorical_accuracy: 0.3433\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1110.0695 - sparse_categorical_accuracy: 0.4505 - val_loss: 1100.3997 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1097.7405 - sparse_categorical_accuracy: 0.6606 - val_loss: 1067.8143 - val_sparse_categorical_accuracy: 0.6702\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1060.6082 - sparse_categorical_accuracy: 0.6525 - val_loss: 1050.1018 - val_sparse_categorical_accuracy: 0.3239\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1045.7990 - sparse_categorical_accuracy: 0.3375 - val_loss: 999.7274 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 997.6241 - sparse_categorical_accuracy: 0.6417 - val_loss: 980.0063 - val_sparse_categorical_accuracy: 0.6558\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 974.3220 - sparse_categorical_accuracy: 0.6435 - val_loss: 971.2011 - val_sparse_categorical_accuracy: 0.3242\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 963.7471 - sparse_categorical_accuracy: 0.3385 - val_loss: 934.2590 - val_sparse_categorical_accuracy: 0.6617\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 934.5663 - sparse_categorical_accuracy: 0.6533 - val_loss: 922.3618 - val_sparse_categorical_accuracy: 0.6752\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 918.0714 - sparse_categorical_accuracy: 0.6608 - val_loss: 881.8231 - val_sparse_categorical_accuracy: 0.6546\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 884.9058 - sparse_categorical_accuracy: 0.5505 - val_loss: 882.4569 - val_sparse_categorical_accuracy: 0.3230\n",
      "Epoch 00071: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0536644750>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "model.fit(train_dataset, epochs=500, validation_data=val_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09aa4362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680381</td>\n",
       "      <td>0.68091</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.809724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.680381    0.68091  0.998647  0.809724"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af.tf_score_summary(model=model, dataset=val_dataset, pos_label=1, \n",
    "                    activation=lambda x: tf.argmax(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5319d0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.680381</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.001918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.680381       0.25  0.000962  0.001918"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af.tf_score_summary(model=model, dataset=val_dataset, pos_label=0, \n",
    "                    activation=lambda x: tf.argmax(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5c1fe72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322997</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.014305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision    recall        f1\n",
       "0  0.322997   0.842105  0.007214  0.014305"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af.tf_score_summary(model=model, dataset=val_dataset, pos_label=1, \n",
    "                    activation=lambda x: tf.argmax(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76a9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ed58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "51bc969f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int64 is not in the list of allowed values: half, bfloat16, float, double\n\t; NodeDef: {{node Softmax}}; Op<name=Softmax; signature=logits:T -> softmax:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]> [Op:Softmax]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17595/3713465839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/data_analysis/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_analysis/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_v2\u001b[0;34m(logits, axis, name)\u001b[0m\n\u001b[1;32m   3818\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3819\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3820\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_2d_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_analysis/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_wrap_2d_function\u001b[0;34m(inputs, compute_op, dim, name)\u001b[0m\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_last_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3739\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m   \u001b[0mdim_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_analysis/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(logits, name)\u001b[0m\n\u001b[1;32m  10862\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10863\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10864\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10865\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10866\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_analysis/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int64 is not in the list of allowed values: half, bfloat16, float, double\n\t; NodeDef: {{node Softmax}}; Op<name=Softmax; signature=logits:T -> softmax:T; attr=T:type,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE]> [Op:Softmax]"
     ]
    }
   ],
   "source": [
    "tf.nn.softmax(np.array([[1, -1], [1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63b17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46076c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f55f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ed072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05193f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNetwork(tf.keras.Model):\n",
    "    # This is the class network we fit on the data.\n",
    "    def __init__(self, final_dim, number_forward_layers=1, hidden_dim=None, education_dim=None,\n",
    "                 occupation_dim=None):\n",
    "\n",
    "        super(ModelNetwork, self).__init__()\n",
    "\n",
    "        self.number_forward_layers = number_forward_layers\n",
    "        self.categorical_dim = 53\n",
    "        if education_dim is not None:\n",
    "            self.education_embedding_layer = tf.keras.layers.Dense(\n",
    "                units=education_dim,\n",
    "                input_dim=(16,)\n",
    "            )\n",
    "            self.categorical_dim = self.categorical_dim - 16 + education_dim\n",
    "        self.education_dim = education_dim\n",
    "\n",
    "        if occupation_dim is not None:\n",
    "            self.occupation_embedding_layer = tf.keras.layers.Dense(\n",
    "                units=occupation_dim,\n",
    "                input_dim=(15,)\n",
    "            )\n",
    "            self.categorical_dim = self.categorical_dim - 15 + occupation_dim\n",
    "        self.occupation_dim = occupation_dim\n",
    "\n",
    "        initial_units = final_dim\n",
    "        if number_forward_layers > 1:\n",
    "            initial_units = hidden_dim\n",
    "        self.initial_block = tf.keras.layers.Dense(\n",
    "            units=initial_units,\n",
    "            activation=\"elu\"\n",
    "        )\n",
    "\n",
    "        self.feed_forward_rest_vet = []\n",
    "        if number_forward_layers > 1:\n",
    "            hidden_units = hidden_dim\n",
    "            for i in np.arange(number_forward_layers - 1):\n",
    "                if i == number_forward_layers - 2:\n",
    "                    hidden_units = final_dim\n",
    "                self.feed_forward_rest_vet.append(\n",
    "                    tf.keras.layers.Dense(\n",
    "                        units=hidden_units, activation=\"elu\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        self.final_linear = tf.keras.layers.Dense(\n",
    "            units=2,\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        continuous_tensor, categorical_tensor = inputs\n",
    "        continuous_tensor = tf.cast(continuous_tensor, tf.float32)\n",
    "        categorical_tensor = tf.cast(categorical_tensor, tf.float32)\n",
    "        if len(continuous_tensor.shape) == 1:\n",
    "            continuous_tensor = tf.reshape(continuous_tensor, (1, -1))\n",
    "            categorical_tensor = tf.reshape(categorical_tensor, (1, -1))\n",
    "\n",
    "        # Process Categorical input\n",
    "        embedding_boolean_edu_array = np.repeat(True, categorical_tensor.shape[1])\n",
    "        embedding_boolean_occ_array = np.repeat(True, categorical_tensor.shape[1])\n",
    "        if self.education_dim is not None:\n",
    "            embedding_boolean_edu_array[9:25] = False\n",
    "            education_tensor = tf.boolean_mask(categorical_tensor, ~embedding_boolean_edu_array, 1)\n",
    "            embedded_education_tensor = self.education_embedding_layer(education_tensor)\n",
    "        if self.occupation_dim is not None:\n",
    "            embedding_boolean_occ_array[32:47] = False\n",
    "            occupation_tensor = tf.boolean_mask(categorical_tensor, ~embedding_boolean_occ_array, 1)\n",
    "            embedded_occupation_tensor = self.occupation_embedding_layer(occupation_tensor)\n",
    "\n",
    "        not_embedding_boolean_array = embedding_boolean_edu_array & embedding_boolean_occ_array\n",
    "        categorical_tensor = tf.boolean_mask(categorical_tensor, not_embedding_boolean_array, 1)\n",
    "        if self.education_dim is not None:\n",
    "            categorical_tensor = tf.concat([categorical_tensor, embedded_education_tensor], 1)\n",
    "        if self.occupation_dim is not None:\n",
    "            categorical_tensor = tf.concat([categorical_tensor, embedded_occupation_tensor], 1)\n",
    "\n",
    "        input_tensor = tf.concat([continuous_tensor, categorical_tensor], 1)\n",
    "\n",
    "        output = self.initial_block(input_tensor)\n",
    "        if self.number_forward_layers != 1:\n",
    "            for i in np.arange(self.number_forward_layers - 1):\n",
    "                output = self.feed_forward_rest_vet[i](output)\n",
    "        output = self.final_linear(output)\n",
    "\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
